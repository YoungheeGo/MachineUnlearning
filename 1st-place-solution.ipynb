{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":56167,"databundleVersionId":6535361,"sourceType":"competition"}],"dockerImageVersionId":30553,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"xMV8jXLTE1He"}},{"cell_type":"markdown","source":["# For-Debugging Notebook\n","\n","This notebook is a notebook for debugging `unlearning` function, based on the following notebook:\n","- https://www.kaggle.com/code/eleni30fillou/run-unlearn-finetune\n","\n","## How to Use\n","\n","1. implement your `unlearning` function;\n","2. turn on `internet on` in the right panel;\n","3. set the variable `USE_MOCK` to `True` in the 2nd code cell;\n","4. (Optional) modity other parameters in the same cell like `n_checkpoints`;\n","5. if your codes work,\n","   - turn off `internet on` in the right panel;\n","   - set the variable `USE_MOCK` to `False` in the 2nd code cell;\n","   - save the notebook;\n","   - and submit!\n","\n","## Updates\n","- Ver.5:\n","  - add a stopwatch decorator\n","  - make `unlearning` return a updated model\n","- Ver.4: fix seed"],"metadata":{"id":"clqZIvUgD1Fl"}},{"cell_type":"code","source":["import os\n","import subprocess\n","\n","import pandas as pd\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.models import resnet18\n","from torch.utils.data import DataLoader, Dataset\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","DEVICE"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T08:20:58.155499Z","iopub.execute_input":"2023-12-01T08:20:58.156334Z","iopub.status.idle":"2023-12-01T08:21:02.303479Z","shell.execute_reply.started":"2023-12-01T08:20:58.1563Z","shell.execute_reply":"2023-12-01T08:21:02.302278Z"},"trusted":true,"id":"L8n_npVVD1Fr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(3047)\n","\n","Gr = torch.Generator()\n","Gr.manual_seed(20)\n","\n","Gf = torch.Generator()\n","Gf.manual_seed(30)\n","\n","Gv = torch.Generator()\n","Gv.manual_seed(40)"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.305238Z","iopub.execute_input":"2023-12-01T08:21:02.305672Z","iopub.status.idle":"2023-12-01T08:21:02.323143Z","shell.execute_reply.started":"2023-12-01T08:21:02.305625Z","shell.execute_reply":"2023-12-01T08:21:02.322086Z"},"trusted":true,"id":"eqz5em0bD1Ft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mock setting\n","\n","import logging\n","import requests\n","import tqdm\n","from torch.utils.data import Subset\n","from torchvision import transforms\n","\n","USE_MOCK: bool = False\n","\n","if USE_MOCK:\n","    logging.warning('Running with Mock')\n","    logging.warning('In this mode, internet access may be required.')\n","\n","    # The number of checkpoints in this mode.\n","    # NOTE: 512 checkpoints are required in this competition.\n","    n_checkpoints = 5\n","\n","    # The directory for a dataset and a pretrained model\n","    mock_dir = './mock'\n","    mock_model_path = os.path.join(mock_dir, \"weights_resnet18_cifar10.pth\")\n","    os.makedirs(mock_dir, exist_ok=True)"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.324795Z","iopub.execute_input":"2023-12-01T08:21:02.325123Z","iopub.status.idle":"2023-12-01T08:21:02.332322Z","shell.execute_reply.started":"2023-12-01T08:21:02.325077Z","shell.execute_reply":"2023-12-01T08:21:02.33124Z"},"trusted":true,"id":"87_HBpcfD1Ft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# It's really important to add an accelerator to your notebook, as otherwise the submission will fail.\n","# We recomment using the P100 GPU rather than T4 as it's faster and will increase the chances of passing the time cut-off threshold.\n","\n","if DEVICE != 'cuda':\n","    raise RuntimeError('Make sure you have added an accelerator to your notebook; the submission will fail otherwise!')"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.334694Z","iopub.execute_input":"2023-12-01T08:21:02.335347Z","iopub.status.idle":"2023-12-01T08:21:02.34651Z","shell.execute_reply.started":"2023-12-01T08:21:02.335309Z","shell.execute_reply":"2023-12-01T08:21:02.345628Z"},"trusted":true,"id":"Y7yfGgN7D1Fu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper functions for loading the hidden dataset.\n","\n","if USE_MOCK:\n","\n","    class DatasetWrapper(Dataset):\n","\n","        def __init__(self, ds: Dataset):\n","            self._ds = ds\n","\n","        def __len__(self):\n","            return len(self._ds)\n","\n","        def __getitem__(self, index):\n","            item = self._ds[index]\n","            result = {\n","                'image': item[0],\n","                'image_id': index,\n","                'age_group': item[1],\n","                'age': item[1],\n","                'person_id': index,\n","            }\n","            return result\n","\n","    def get_dataset(batch_size, retain_ratio=0.98, thinning_param: int=1, root=mock_dir) -> tuple[DataLoader, DataLoader, DataLoader]:\n","\n","        # utils\n","        normalize = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ])\n","\n","        # create dataset\n","        train_ds = DatasetWrapper(torchvision.datasets.CIFAR10(root=mock_dir, train=True, download=True, transform=normalize))\n","        retain_ds = Subset(train_ds, range(0, int(len(train_ds)*retain_ratio), thinning_param))\n","        forget_ds = Subset(train_ds, range(int(len(train_ds)*retain_ratio), len(train_ds), thinning_param))\n","        val_ds = DatasetWrapper(torchvision.datasets.CIFAR10(root=mock_dir, train=False, download=True, transform=normalize))\n","\n","        retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n","        forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n","        validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n","\n","        return retain_loader, forget_loader, validation_loader\n","\n","    # For test\n","#     for sample in get_dataset(3)[0]:\n","#         print(sample)\n","#         break\n","\n","else:\n","    def load_example(df_row):\n","        image = torchvision.io.read_image(df_row['image_path'])\n","        result = {\n","            'image': image,\n","            'image_id': df_row['image_id'],\n","            'age_group': df_row['age_group'],\n","            'age': df_row['age'],\n","            'person_id': df_row['person_id']\n","        }\n","        return result\n","\n","\n","    class HiddenDataset(Dataset):\n","        '''The hidden dataset.'''\n","        def __init__(self, split='train'):\n","            super().__init__()\n","            self.examples = []\n","\n","            df = pd.read_csv(f'/kaggle/input/neurips-2023-machine-unlearning/{split}.csv')\n","            df['image_path'] = df['image_id'].apply(lambda x: os.path.join('/kaggle/input/neurips-2023-machine-unlearning/', 'images', x.split('-')[0], x.split('-')[1] + '.png'))\n","            df = df.sort_values(by='image_path')\n","            df.apply(lambda row: self.examples.append(load_example(row)), axis=1)\n","            if len(self.examples) == 0:\n","                raise ValueError('No examples.')\n","\n","        def __len__(self):\n","            return len(self.examples)\n","\n","        def __getitem__(self, idx):\n","            example = self.examples[idx]\n","            image = example['image']\n","            image = image.to(torch.float32)\n","            example['image'] = image\n","            return example\n","\n","\n","    def get_dataset(batch_size):\n","        '''Get the dataset.'''\n","        retain_ds = HiddenDataset(split='retain')\n","        forget_ds = HiddenDataset(split='forget')\n","        val_ds = HiddenDataset(split='validation')\n","\n","        retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True, generator=Gr)\n","        forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True, generator=Gf)\n","        validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, generator=Gv)\n","        #retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n","        #forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n","        #validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n","\n","        return retain_loader, forget_loader, validation_loader"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.348018Z","iopub.execute_input":"2023-12-01T08:21:02.348358Z","iopub.status.idle":"2023-12-01T08:21:02.371775Z","shell.execute_reply.started":"2023-12-01T08:21:02.348332Z","shell.execute_reply":"2023-12-01T08:21:02.370707Z"},"trusted":true,"id":"bKkmixesD1Fu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Utils\n","from contextlib import contextmanager\n","import time\n","\n","@contextmanager\n","def stopwatch(name='STOPWATCH'):\n","    s = time.time()\n","    try:\n","        yield\n","    finally:\n","        print(f\"{name}: {time.time()-s} seconds passed\")\n","\n","# for test\n","# with stopwatch():\n","#     for i in range(5):\n","#         time.sleep(1)"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.373045Z","iopub.execute_input":"2023-12-01T08:21:02.373954Z","iopub.status.idle":"2023-12-01T08:21:02.391797Z","shell.execute_reply.started":"2023-12-01T08:21:02.373926Z","shell.execute_reply":"2023-12-01T08:21:02.39084Z"},"trusted":true,"id":"DklMkCcAD1Fv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n","def kl_loss_sym(x,y):\n","    kl_loss = nn.KLDivLoss(reduction='batchmean')\n","    return kl_loss(nn.LogSoftmax(dim=-1)(x),y)\n","def unlearning(\n","        net,\n","        retain_loader,\n","        forget_loader,\n","        val_loader,\n","):\n","    \"\"\"Simple unlearning by finetuning.\"\"\"\n","    print('-----------------------------------')\n","    epochs = 8\n","    retain_bs = 256\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=0.005,\n","                          momentum=0.9, weight_decay=0)\n","    optimizer_retain = optim.SGD(net.parameters(), lr=0.001*retain_bs/64, momentum=0.9, weight_decay=1e-2)\n","    ##the learning rate is associated with the batchsize we used\n","    optimizer_forget = optim.SGD(net.parameters(), lr=3e-4, momentum=0.9, weight_decay=0)\n","    total_step = int(len(forget_loader)*epochs)\n","    retain_ld = DataLoader(retain_loader.dataset, batch_size=retain_bs, shuffle=True)\n","    retain_ld4fgt = DataLoader(retain_loader.dataset, batch_size=256, shuffle=True)\n","    scheduler = CosineAnnealingLR(optimizer_forget, T_max=total_step, eta_min=1e-6)\n","    if USE_MOCK: ##Use some Local Metric as reference\n","        net.eval()\n","        print('Forget')\n","        evaluation(net, forget_loader, criterion)\n","        print('Valid')\n","        evaluation(net, validation_loader, criterion)\n","    net.train()\n","    for sample in forget_loader: ##First Stage\n","        inputs = sample[\"image\"]\n","        inputs = inputs.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        uniform_label = torch.ones_like(outputs).to(DEVICE) / outputs.shape[1] ##uniform pseudo label\n","        loss = kl_loss_sym(outputs, uniform_label) ##optimize the distance between logits and pseudo labels\n","        loss.backward()\n","        optimizer.step()\n","    if USE_MOCK:\n","        print('Forget')\n","        evaluation(net,forget_loader,criterion)\n","        print('Valid')\n","        evaluation(net, validation_loader,criterion)\n","        print(f'epoch={epochs} and retain batch_sz={retain_bs}')\n","    net.train()\n","    for ep in range(epochs): ##Second Stage\n","        net.train()\n","        for sample_forget, sample_retain in zip(forget_loader, retain_ld4fgt):##Forget Round\n","            t = 1.15 ##temperature coefficient\n","            inputs_forget,inputs_retain = sample_forget[\"image\"],sample_retain['image']\n","            inputs_forget, inputs_retain = inputs_forget.to(DEVICE), inputs_retain.to(DEVICE)\n","            optimizer_forget.zero_grad()\n","            outputs_forget,outputs_retain = net(inputs_forget),net(inputs_retain).detach()\n","            loss = (-1 * nn.LogSoftmax(dim=-1)(outputs_forget @ outputs_retain.T/t)).mean() ##Contrastive Learning loss\n","            loss.backward()\n","            optimizer_forget.step()\n","            scheduler.step()\n","        for sample in retain_ld: ##Retain Round\n","            inputs, labels = sample[\"image\"],sample[\"age_group\"]\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            optimizer_retain.zero_grad()\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer_retain.step()\n","        if USE_MOCK:\n","            print(f'epoch {ep}:')\n","            print('Retain')\n","            evaluation(net, retain_ld, criterion)\n","            print('Forget')\n","            evaluation(net, forget_loader, criterion)\n","            print('Valid')\n","            evaluation(net, validation_loader, criterion)\n","    print('-----------------------------------')\n","    return net\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.394818Z","iopub.execute_input":"2023-12-01T08:21:02.39562Z","iopub.status.idle":"2023-12-01T08:21:02.419559Z","shell.execute_reply.started":"2023-12-01T08:21:02.395584Z","shell.execute_reply":"2023-12-01T08:21:02.41852Z"},"trusted":true,"id":"nNCkMZKPD1Fw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluation(net, dataloader, criterion, device = 'cuda'): ##evaluation function\n","    net.eval()\n","    total_samp = 0\n","    total_acc = 0\n","    total_loss = 0.0\n","    for sample in dataloader:\n","        images, labels = sample['image'].to(device), sample['age_group'].to(device)\n","        _pred = net(images)\n","        total_samp+=len(labels)\n","        #print(f'total_samp={total_samp}')\n","        loss = criterion(_pred, labels)\n","        total_loss += loss.item()\n","        total_acc+=(_pred.max(1)[1] == labels).float().sum().item()\n","        #print(f'total_acc={total_acc}')\n","    #print(f'total_sample={total_samp}')\n","    mean_loss = total_loss / len(dataloader)\n","    mean_acc = total_acc/total_samp\n","    print(f'loss={mean_loss}')\n","    print(f'acc={mean_acc}')\n","    return"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.420689Z","iopub.execute_input":"2023-12-01T08:21:02.421416Z","iopub.status.idle":"2023-12-01T08:21:02.437408Z","shell.execute_reply.started":"2023-12-01T08:21:02.421382Z","shell.execute_reply":"2023-12-01T08:21:02.436451Z"},"trusted":true,"id":"m8l1iDOMD1Fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","if USE_MOCK:\n","\n","    # NOTE: Almost same as the original codes\n","\n","    # Download\n","    if not os.path.exists(mock_model_path):\n","        response = requests.get(\"https://storage.googleapis.com/unlearning-challenge/weights_resnet18_cifar10.pth\")\n","        open(mock_model_path, \"wb\").write(response.content)\n","\n","    os.makedirs('/kaggle/tmp', exist_ok=True)\n","    retain_loader, forget_loader, validation_loader = get_dataset(64)\n","    net = resnet18(weights=None, num_classes=10)\n","    net.to(DEVICE)\n","    for i in tqdm.trange(n_checkpoints):\n","        net.load_state_dict(torch.load(mock_model_path))\n","        net_ = unlearning(net, retain_loader, forget_loader, validation_loader)\n","        state = net_.state_dict()\n","        torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n","\n","    # Ensure that submission.zip will contain exactly 512 checkpoints\n","    # (if this is not the case, an exception will be thrown).\n","    unlearned_ckpts = os.listdir('/kaggle/tmp')\n","    if len(unlearned_ckpts) != n_checkpoints:\n","        raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n","\n","    subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n","\n","else:\n","    if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n","        # mock submission\n","        subprocess.run('touch submission.zip', shell=True)\n","    else:\n","\n","        # Note: it's really important to create the unlearned checkpoints outside of the working directory\n","        # as otherwise this notebook may fail due to running out of disk space.\n","        # The below code saves them in /kaggle/tmp to avoid that issue.\n","\n","        os.makedirs('/kaggle/tmp', exist_ok=True)\n","        retain_loader, forget_loader, validation_loader = get_dataset(64)\n","        net = resnet18(weights=None, num_classes=10)\n","        net.to(DEVICE)\n","        for i in range(512):\n","            net.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n","            net_ = unlearning(net, retain_loader, forget_loader, validation_loader)\n","            state = net_.state_dict()\n","            torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n","\n","        # Ensure that submission.zip will contain exactly 512 checkpoints\n","        # (if this is not the case, an exception will be thrown).\n","        unlearned_ckpts = os.listdir('/kaggle/tmp')\n","        if len(unlearned_ckpts) != 512:\n","            raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n","\n","        subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:21:02.438607Z","iopub.execute_input":"2023-12-01T08:21:02.439368Z","iopub.status.idle":"2023-12-01T08:22:04.703415Z","shell.execute_reply.started":"2023-12-01T08:21:02.439333Z","shell.execute_reply":"2023-12-01T08:22:04.701913Z"},"trusted":true,"id":"jWqDlvZOD1Fz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fhh7tpbxELDE"},"execution_count":null,"outputs":[]}]}